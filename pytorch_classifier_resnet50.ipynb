{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72090e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.ndimage import binary_erosion\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ca88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = \"/home/bandyadkas/cellcyle/data/\"\n",
    "images = \"/mnt/efs/woods_hole/bbbc_cellcycle/model_data/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05b0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "        'train': transforms.Compose([\n",
    "            #transforms.Resize([224,224]), # Resizing the image as the VGG only take 224 x 244 as input size\n",
    "            #transforms.RandomHorizontalFlip(), # Flip the data horizontally\n",
    "            #TODO if it is needed, add the random crop\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            #transforms.Resize([224,224]),\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean=(0), std=(1))\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73372615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32266\n"
     ]
    }
   ],
   "source": [
    "all_images = datasets.ImageFolder(images,transform=transform['train'])\n",
    "print(len(all_images))\n",
    "#all_images = torchvision.datasets.DatasetFolder(\n",
    "#    \"/mnt/efs/woods_hole/bbbc_cellcycle/CellCycle/\",\n",
    "#    imageio.imread, (\"merged.jpg\"), transform=transform)\n",
    "#print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77069f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22586 4839 4841\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.7 * len(all_images))\n",
    "val_size = int(0.15 * len(all_images))\n",
    "test_size = len(all_images) - (train_size + val_size)\n",
    "print(train_size, val_size, test_size)\n",
    "assert train_size + val_size + test_size == len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b21067",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(all_images, [train_size, val_size, test_size])\n",
    "#train_set, val_set, test_set = torch.utils.data.random_split(all_images, [22538, 4829, 4831])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf02c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_weights(subset,full_dataset):\n",
    "    ys = np.array([y for _, y in subset])\n",
    "    counts = np.bincount(ys)\n",
    "    label_weights = 1.0 / counts\n",
    "    weights = label_weights[ys]\n",
    "\n",
    "    print(\"Number of images per class:\")\n",
    "    for c, n, w in zip(full_dataset.classes, counts, label_weights):\n",
    "        print(f\"\\t{c}:\\tn={n}\\tweight={w}\")\n",
    "        \n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abbd9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images per class:\n",
      "\tAnaphase:\tn=11\tweight=0.09090909090909091\n",
      "\tG1:\tn=9991\tweight=0.00010009008107296567\n",
      "\tG2:\tn=5991\tweight=0.00016691704223001168\n",
      "\tMetaphase:\tn=54\tweight=0.018518518518518517\n",
      "\tProphase:\tn=424\tweight=0.0023584905660377358\n",
      "\tS:\tn=6097\tweight=0.0001640150893882237\n",
      "\tTelophase:\tn=18\tweight=0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_weights = _get_weights(train_set,all_images)\n",
    "train_sampler = WeightedRandomSampler(train_weights, len(train_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30faaed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=8, drop_last=True, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_set, batch_size=8 , drop_last=True, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=8, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241c3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up tensorboard\n",
    "writer = SummaryWriter('/mnt/efs/woods_hole/bbbc_cellcycle/classify_cellCycle_bandyadka/runs/cellcycle_resnet50_discrete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45be449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9966af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model = torchvision.models.resnet50(pretrained = False, progress  = True, num_classes=7)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06bf3e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use device cuda for training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet50_model.to(device)\n",
    "print(f\"Will use device {device} for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdd3da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model,loss,train_dataloader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += l\n",
    "        num_batches += 1\n",
    "\n",
    "    return epoch_loss/num_batches\n",
    "\n",
    "def evaluate(model, loss, dataloader):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader):\n",
    "\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            val_loss = loss(logits,y)\n",
    "            \n",
    "            probs = torch.nn.Softmax(dim=1)(logits)\n",
    "            predictions = torch.argmax(probs, dim=1)\n",
    "\n",
    "            correct += int(torch.sum(predictions == y).cpu().detach().numpy())\n",
    "            total += len(y)\n",
    "\n",
    "        accuracy = correct/total\n",
    "\n",
    "    return accuracy, val_loss\n",
    "\n",
    "def validate(model,loss, validation_dataloader):\n",
    "    '''Evaluate prediction accuracy on the validation dataset.'''\n",
    "    \n",
    "    model.eval()\n",
    "    return evaluate(model,loss,validation_dataloader)\n",
    "\n",
    "def test(model,loss,test_dataloader):\n",
    "    '''Evaluate prediction accuracy on the test dataset.'''\n",
    "    \n",
    "    model.eval() \n",
    "    return evaluate(model, loss,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "epochs = 100\n",
    "for epoch in range(epochs+1):\n",
    "    while step < epoch: \n",
    "    \n",
    "        epoch_loss = train(resnet50_model,loss_fn,train_loader)\n",
    "        print(f\"epoch {epoch}, training loss={epoch_loss}\")\n",
    "    \n",
    "        validation_accuracy, validation_loss = validate(resnet50_model, loss_fn,val_loader)\n",
    "        print(f\"epoch {epoch}, validation accuracy={validation_accuracy}\")\n",
    "    \n",
    "        writer.add_scalar('Loss/train', epoch_loss.cpu().detach().numpy(),step)      \n",
    "        writer.add_scalar('Accuracy/validation', validation_accuracy,step)\n",
    "        writer.add_scalar('Loss/validation', validation_loss.cpu().detach().numpy(),step)\n",
    "        \n",
    "        if step == 100:\n",
    "            state = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': resnet50_model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "            torch.save(state, \"/mnt/efs/woods_hole/bbbc_cellcycle/classify_cellCycle_bandyadka/modelsave.pth\")\n",
    "        \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45cd1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = torch.load(\"/mnt/efs/woods_hole/bbbc_cellcycle/classify_cellCycle_bandyadka/modelsave.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4204d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 605/605 [00:23<00:00, 25.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test accuracy: 0.2721074380165289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, test_loss = test(resnet50_model,loss_fn,test_loader)\n",
    "print(f\"final test accuracy: {test_accuracy}\")\n",
    "writer.add_scalar('Accuracy/test', test_accuracy)\n",
    "#writer.add_scalar('Loss/test', test_loss.cpu().detach().numpy(),step)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3780934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# predict the test dataset\n",
    "def predict(model, dataset):\n",
    "    dataset_prediction = []\n",
    "    dataset_groundtruth = []\n",
    "    with torch.no_grad():\n",
    "        for x, y_true in dataset:\n",
    "            inp = x[None].cuda()\n",
    "            y_pred = model(inp)\n",
    "            dataset_prediction.append(y_pred.argmax().cpu().numpy())\n",
    "            dataset_groundtruth.append(y_true)\n",
    "    \n",
    "    return np.array(dataset_prediction), np.array(dataset_groundtruth)\n",
    "            \n",
    "    # create seabvorn heatmap with required labels\n",
    "    #sns.heatmap(flights_df, xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "    ax=sns.heatmap(cm, annot=annot, fmt='', vmax=30, xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "    ax.set_title(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Plot confusion matrix \n",
    "# orginally from Runqi Yang; \n",
    "# see https://gist.github.com/hitvoice/36cf44689065ca9b927431546381a3f7\n",
    "def cm_analysis(y_true, y_pred, title, figsize=(10,10)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    labels = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    x_axis_labels = ['Anaphase', 'G1', 'G2', 'Metaphase', 'Prophase', 'S', 'Telophase'] # labels for x-axis\n",
    "    y_axis_labels = ['Anaphase', 'G1', 'G2', 'Metaphase', 'Prophase', 'S', 'Telophase'] # labels for y-axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = predict(resnet50_model, test_set)\n",
    "cm_analysis(y_true, y_pred, \"Confusion matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
